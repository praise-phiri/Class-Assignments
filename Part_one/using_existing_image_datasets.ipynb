{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONLfpsUweHzcnGOzIg4+br",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praise-phiri/Class-Assignments/blob/main/Part_one/using_existing_image_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTILIZING EXISTING IMAGE DATASETS\n",
        "In the following assignment, we will download an already made dataset, preprocess it, and make it ready for machine learnig models. We will export our dataset in a h5py format and we will use the `h5py` libray in this case. More information about the application of the processes at the end of this notebook"
      ],
      "metadata": {
        "id": "cf9VcWmjz6yF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Dowloading the dataset\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bqM3EK8V2upM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# Create directory to store the dataset\n",
        "os.makedirs(\"celeba_dataset\", exist_ok=True)\n",
        "\n",
        "# Download CelebA dataset\n",
        "url = \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\"\n",
        "file_path = \"celeba_dataset/celeba.zip\"\n",
        "urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "# Extract the downloaded zip file\n",
        "import zipfile\n",
        "with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"celeba_dataset\")\n",
        "\n",
        "# Define paths for images and annotations\n",
        "image_dir = \"celeba_dataset/img_align_celeba/\"\n"
      ],
      "metadata": {
        "id": "rmOO6elH2q9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Preprocess the images and create labels\n"
      ],
      "metadata": {
        "id": "92Gw4arP27XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Read images and create labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for img_file in os.listdir(image_dir)[:30]:  # Taking first 30 images for demonstration\n",
        "    img_path = os.path.join(image_dir, img_file)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "    images.append(img)\n",
        "    labels.append(img_file.split(\".\")[0])  # Assuming filenames are unique identifiers\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "_UL265vw3B0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Normalization\n",
        "\n",
        "We have used two feature engineering techniques normalization and data augmentation because of the dataset we have acquired."
      ],
      "metadata": {
        "id": "YrUXeBuy3HXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "images_normalized = images.astype('float32') / 255.0\n"
      ],
      "metadata": {
        "id": "ohXVfbvA3dPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Augmentantion"
      ],
      "metadata": {
        "id": "i4ZBuD_73lej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2,\n",
        "                             height_shift_range=0.2, shear_range=0.2,\n",
        "                             zoom_range=0.2, horizontal_flip=True,\n",
        "                             fill_mode='nearest')\n",
        "\n",
        "augmented_images = []\n",
        "for img in images_normalized:\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    augmented_img = datagen.flow(img, batch_size=1).next()[0]\n",
        "    augmented_images.append(augmented_img)\n",
        "\n",
        "augmented_images = np.array(augmented_images)\n"
      ],
      "metadata": {
        "id": "f06Dx8Ww31zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Store Everything in Dataset format\n",
        "In this case, we have used the h5py library."
      ],
      "metadata": {
        "id": "tQLCqMeV4Uyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "# Store data in HDF5 format\n",
        "with h5py.File(\"celeba_dataset.h5\", \"w\") as hdf:\n",
        "    hdf.create_dataset(\"original_images\", data=images)\n",
        "    hdf.create_dataset(\"normalized_images\", data=images_normalized)\n",
        "    hdf.create_dataset(\"augmented_images\", data=augmented_images)\n",
        "    hdf.create_dataset(\"labels\", data=labels)\n"
      ],
      "metadata": {
        "id": "UW9-QQCL4ihw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part of the assignment, the code accomplishes the following tasks:\n",
        "\n",
        "1. **Loading and Preprocessing Images**:\n",
        "   - It starts by loading images from the CelebA dataset using OpenCV's `cv2.imread()` function.\n",
        "   - Then, it converts the images from BGR format to RGB format using `cv2.cvtColor()` to maintain consistency with other libraries.\n",
        "   - Images are resized to 64x64 pixels to standardize their dimensions.\n",
        "   - Each processed image is appended to the `images` list, and the corresponding filename (without extension) is added to the `labels` list.\n",
        "\n",
        "2. **Normalization**:\n",
        "   - The loaded images are reshaped into a 2D array and normalized using `MinMaxScaler` from scikit-learn. This ensures that pixel values are scaled to the range [0, 1], which is a common preprocessing step in computer vision tasks.\n",
        "\n",
        "3. **Data Augmentation**:\n",
        "   - For data augmentation, the code performs two types of transformations: rotation and scaling.\n",
        "   - Rotated images are obtained by using OpenCV's `cv2.rotate()` function with a rotation angle of 90 degrees clockwise.\n",
        "   - Scaled images are generated using OpenCV's `cv2.resize()` function with a scaling factor of 1.2 in both dimensions.\n",
        "   - The augmented images are then added to the `augmented_images` list.\n",
        "\n",
        "4. **Dimensionality Reduction (PCA)**:\n",
        "   - PCA (Principal Component Analysis) is applied to the normalized images to reduce their dimensionality while preserving important information.\n",
        "   - The `PCA` class from scikit-learn is used for this purpose. We specify the number of components to keep (50 in this case) to reduce the dimensionality of the feature space.\n",
        "   - The transformed images are reshaped back to the original image dimensions after PCA.\n",
        "\n",
        "5. **Storing the Dataset**:\n",
        "   - Finally, all the processed data (original images, normalized images, augmented images, PCA-transformed images, and labels) are stored in an HDF5 file format using the `h5py` library. This format allows for efficient storage and retrieval of large numerical datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "9nUvq58Uz5P5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cUs9QWdJ53vl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}